{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AND+XORperceptrons.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlEtfRu+N9P4OTDIuz9swG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepSmeag/ML_Colab/blob/main/AND%2BXORperceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSD-ubxddEbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ac7f57-c12a-48dd-b430-cb1763f03d38"
      },
      "source": [
        "!git clone https://github.com/DeepSmeag/ML_Colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_Colab'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 66 (delta 30), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTnxk8iadYti"
      },
      "source": [
        "First we load the project so we get access to the files. Then we read the files of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdoKlQNwdYRj",
        "outputId": "5bfee7c2-eca2-4153-bc61-8da24ee4b5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def read_file(file_path):\n",
        "  dataset=[]\n",
        "  with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.strip()\n",
        "      parts = line.split(',')\n",
        "      x0,x1,y1,y2 = float(parts[0]), float(parts[1]), float(parts[2]), float(parts[3])\n",
        "      dataset.append((x0,x1,y1,y2))\n",
        "    return dataset\n",
        "\n",
        "dataset = read_file('ML_Colab/datasetAND+XOR.csv')\n",
        "\"\"\"it could also work with numpy and/or pandas to read the whole csv file at the\n",
        "same time, probably more efficient too\n",
        "\"\"\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'it could also work with numpy and/or pandas to read the whole csv file at the\\nsame time, probably more efficient too\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBz_LId6fAam"
      },
      "source": [
        "We now have our dataset ready for use, next let's go and make the vectors for use with our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8Oo0fsfMsz"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndtPJIvjWle"
      },
      "source": [
        "#first layer is input, meaning we take the first 2 columns of the dataset\n",
        "num_trains = len(dataset)\n",
        "X = np.ones((num_trains,1)) \n",
        "#now we add the bias to every training instance\n",
        "X = np.append(X, np.array(dataset)[:,0:2], axis=1)\n",
        "# now we take the outputs\n",
        "Y = np.array(dataset)[:,2:4]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCs5cTggxQZ",
        "outputId": "07de521e-d987-47c5-e78c-47680ab1d272"
      },
      "source": [
        "#now we create Numpy arrays so that we have our weights\n",
        "#the first layer\n",
        "W1 = np.random.uniform(-1,1,(3,3))\n",
        "#the second\n",
        "W2 = np.random.uniform(-1,1,(4,2))\n",
        "print(\"W1:\\n\",W1,\"\\n\")\n",
        "print(\"W2:\\n\",W2,\"\\n\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1:\n",
            " [[-0.95586837  0.93349817  0.95214154]\n",
            " [ 0.06574888 -0.49372003 -0.66550179]\n",
            " [ 0.90333154 -0.65779367  0.34961274]] \n",
            "\n",
            "W2:\n",
            " [[ 0.6113833   0.85550519]\n",
            " [ 0.74877283  0.57283235]\n",
            " [-0.43315179  0.03552481]\n",
            " [-0.28665714  0.37042094]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTXmd0W6n3sY"
      },
      "source": [
        "#Now we're getting to the fun stuff\n",
        "#First, defining the necessary functions\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "#Forward Propagation\n",
        "def forward_prop(X, W1, W2):\n",
        "  #calculating the steps\n",
        "  z2 = np.matmul(X, W1)\n",
        "  a2 = sigmoid(z2)\n",
        "  a2 = np.insert(a2, 3, np.ones((num_trains,)), axis = 1)\n",
        "  z3 = np.matmul(a2, W2)\n",
        "  y_hat = sigmoid(z3)\n",
        "  return z2, a2, z3, y_hat\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCjkG9R3u74D",
        "outputId": "bf5d0c88-0fe8-4058-ece5-53e58cc619c7"
      },
      "source": [
        "#Ok, so that was forward propagation\n",
        "#Now, the NN should also be able to learn, so we have to implement Backprop\n",
        "#Since we're guessing at best at the moment as to the correct outputs\n",
        "#We have to define several functions for Backprop to work\n",
        "#These include the partial derivatives with which we'll update the weights matrices W1 and W2\n",
        "#And also the backprop itself which will go over epochs or whatever we may call it\n",
        "\n",
        "# matrices sizes\n",
        "# X = num_trains x 3\n",
        "# W1 = 3 x 3\n",
        "# Z2 = num_trains x 3\n",
        "# A2 = num_trains x 4 by adding a collumn of ones at the end\n",
        "# W2 = 4 x 2\n",
        "# Z3 = num_trains x 2\n",
        "# A3 = Y_hat = num_trains x 2\n",
        "\n",
        "\n",
        "def sigmoid_gradient(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))\n",
        "def derivative(z2, a2, z3, y_hat, training_point):\n",
        "  dz3 = sigmoid_gradient(z3(training_point, :)) # 1 x 2\n",
        "  dw2 = np.matmul(a2(training_point, :).transpose(), dz3) # 4 x 2\n",
        "  dz2 = sigmoid_gradient(z2(training_point, :)) # 1 x 3\n",
        "  temp1 = np.matmul(dz3, W2.transpose()) # 1 x 4\n",
        "  temp1 = np.delete(temp1, 3, 1) # drop last column because it's for bias, 1 x 3\n",
        "  temp2 = np.multiply(temp1, dz2) # num_trains x 3\n",
        "  dw1 = np.matmul(temp2.transpose(), X(training_point, :)) # 3 x 3\n",
        "  return dw1, dw2\n",
        "\n",
        "def backprop(num_trains, learning_rate, X, W1, W2):\n",
        "  z2, a2, z3, y_hat = forward_prop(X, W1, W2)\n",
        "  for training_point in range(num_trains):\n",
        "    print(\"current_training_point: \", i+1, \"\\n\")\n",
        "    \n",
        "    dw1, dw2 = derivative(z2, a2, z3, y_hat, training_point)\n",
        "    W1 = np.subtract(W1, learning_rate * dw1)\n",
        "    W2 = np.subtract(W2, learning_rate * dw2)\n",
        "  with open(\"ML_Colab/AND+XORmodelW1.csv\", 'w') as fw1:\n",
        "    np.savetxt(fw1 , W1 , fmt='%s', delimiter=',')\n",
        "  with open(\"ML_Colab/AND+XORmodelW2.csv\", 'w') as fw2:\n",
        "    np.savetxt(fw2 , W2 , fmt='%s', delimiter=',')\n",
        "\n",
        "backprop(10, 0.1, X, W1, W2)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1 \n",
            "\n",
            "epoch:  2 \n",
            "\n",
            "epoch:  3 \n",
            "\n",
            "epoch:  4 \n",
            "\n",
            "epoch:  5 \n",
            "\n",
            "epoch:  6 \n",
            "\n",
            "epoch:  7 \n",
            "\n",
            "epoch:  8 \n",
            "\n",
            "epoch:  9 \n",
            "\n",
            "epoch:  10 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULlxQRYnz44_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ee3ac7-ec00-4b5f-90f4-4ec46fb25250"
      },
      "source": [
        "new_w1 = np.genfromtxt('ML_Colab/AND+XORmodelW1.csv', delimiter=',')\n",
        "\n",
        "new_w2 = np.genfromtxt('ML_Colab/AND+XORmodelW2.csv', delimiter=',')\n",
        "\n",
        "Null, Null, Null, y_hat = forward_prop(X, new_w1, new_w2)\n",
        "y_hat = np.rint(y_hat)\n",
        "print(y_hat)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " ...\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZbcXrs0HcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c78e32e-ebc3-4848-ae1b-6401d2e59534"
      },
      "source": [
        "Y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}