{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AND+XORperceptrons.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP99f/EiRE26eKHNgzKEOM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepSmeag/ML_Colab/blob/main/AND%2BXORperceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSD-ubxddEbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b582f5-5ad4-4d56-b406-e51f1accb305"
      },
      "source": [
        "!git clone https://github.com/DeepSmeag/ML_Colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML_Colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTnxk8iadYti"
      },
      "source": [
        "First we load the project so we get access to the files. Then we read the files of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdoKlQNwdYRj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63098996-7ad6-4a37-f59a-1f18a33770b6"
      },
      "source": [
        "def read_file(file_path):\n",
        "  dataset=[]\n",
        "  with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.strip()\n",
        "      parts = line.split(',')\n",
        "      x0,x1,y1,y2 = float(parts[0]), float(parts[1]), float(parts[2]), float(parts[3])\n",
        "      dataset.append((x0,x1,y1,y2))\n",
        "    return dataset\n",
        "\n",
        "dataset = read_file('ML_Colab/datasetAND+XOR.csv')\n",
        "\"\"\"it could also work with numpy and/or pandas to read the whole csv file at the\n",
        "same time, probably more efficient too\n",
        "\"\"\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'it could also work with numpy and/or pandas to read the whole csv file at the\\nsame time, probably more efficient too\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBz_LId6fAam"
      },
      "source": [
        "We now have our dataset ready for use, next let's go and make the vectors for use with our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8Oo0fsfMsz"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndtPJIvjWle"
      },
      "source": [
        "#first layer is input, meaning we take the first 2 columns of the dataset\n",
        "num_trains = len(dataset)\n",
        "X = np.ones((num_trains,1))\n",
        "#now we add the bias to every training instance\n",
        "X = np.append(X, np.array(dataset)[:,0:2], axis=1)\n",
        "# now we take the outputs\n",
        "Y = np.array(dataset)[:,2:4]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCs5cTggxQZ",
        "outputId": "22833654-e234-4b58-e32d-b8397be2ca8c"
      },
      "source": [
        "#now we create Numpy arrays so that we have our weights\n",
        "#the first layer\n",
        "W1 = np.random.uniform(-1,1,(3,3))\n",
        "#the second\n",
        "W2 = np.random.uniform(-1,1,(4,2))\n",
        "print(\"W1:\\n\",W1,\"\\n\")\n",
        "print(\"W2:\\n\",W2,\"\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1:\n",
            " [[-0.42903015 -0.67281166  0.38566842]\n",
            " [-0.59663074 -0.21985404 -0.09089122]\n",
            " [ 0.94226927  0.58900224  0.03341782]] \n",
            "\n",
            "W2:\n",
            " [[ 0.7135727   0.31560464]\n",
            " [ 0.41013903 -0.75344989]\n",
            " [-0.26131313 -0.50185821]\n",
            " [ 0.46870929 -0.17162657]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTXmd0W6n3sY"
      },
      "source": [
        "#Now we're getting to the fun stuff\n",
        "#First, defining the necessary functions\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "#Forward Propagation\n",
        "def forward_prop(X, W1, W2):\n",
        "  #calculating the steps\n",
        "  z2 = np.matmul(X, W1)\n",
        "  a2 = sigmoid(z2)\n",
        "  a2 = np.insert(a2, 3, np.ones((num_trains,)), axis = 1)\n",
        "  z3 = np.matmul(a2, W2)\n",
        "  y_hat = sigmoid(z3)\n",
        "  return z2, a2, z3, y_hat\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "nCjkG9R3u74D",
        "outputId": "e579bcd6-20bd-4f95-f471-416d009c0e7b"
      },
      "source": [
        "#Ok, so that was forward propagation\n",
        "#Now, the NN should also be able to learn, so we have to implement Backprop\n",
        "#Since we're guessing at best at the moment as to the correct outputs\n",
        "#We have to define several functions for Backprop to work\n",
        "#These include the partial derivatives with which we'll update the weights matrices W1 and W2\n",
        "#And also the backprop itself which will go over epochs or whatever we may call it\n",
        "\n",
        "# matrices sizes\n",
        "# X = num_trains x 3\n",
        "# W1 = 3 x 3\n",
        "# Z2 = num_trains x 3\n",
        "# A2 = num_trains x 4 by adding a collumn of ones at the end\n",
        "# W2 = 4 x 2\n",
        "# Z3 = num_trains x 2\n",
        "# A3 = Y_hat = num_trains x 2\n",
        "\n",
        "\n",
        "def sigmoid_gradient(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))\n",
        "def derivative(z2, a2, z3, y_hat, training_point):\n",
        "  dz3 = sigmoid_gradient(z3[training_point, :]) # 1 x 2\n",
        "  dw2 = np.matmul(np.matrix(a2[training_point, :]).T, np.matrix(dz3)) # 4 x 2\n",
        "  dz2 = np.matrix(sigmoid_gradient(z2[training_point, :])) # 1 x 3\n",
        "\n",
        "  print(dz2.shape)\n",
        "\n",
        "  temp1 = np.matmul(dz3, W2.transpose()) # 1 x 4\n",
        "  temp1 = np.delete(temp1, 3) # drop last column because it's for bias, 1 x 3\n",
        "  temp2 = np.multiply(temp1, dz2) # num_trains x 3\n",
        "  dw1 = np.matmul(temp2.transpose(), X[training_point, :]) # 3 x 3\n",
        "  return dw1, dw2\n",
        "\n",
        "def backprop(num_trains, learning_rate, X, W1, W2):\n",
        "  z2, a2, z3, y_hat = forward_prop(X, W1, W2)\n",
        "  for training_point in range(num_trains):\n",
        "    print(\"current_training_point: \", training_point+1, \"\\n\")\n",
        "    \n",
        "    dw1, dw2 = derivative(z2, a2, z3, y_hat, training_point)\n",
        "    W1 = np.subtract(W1, learning_rate * dw1)\n",
        "    W2 = np.subtract(W2, learning_rate * dw2)\n",
        "  with open(\"ML_Colab/AND+XORmodelW1.csv\", 'w') as fw1:\n",
        "    np.savetxt(fw1 , W1 , fmt='%s', delimiter=',')\n",
        "  with open(\"ML_Colab/AND+XORmodelW2.csv\", 'w') as fw2:\n",
        "    np.savetxt(fw2 , W2 , fmt='%s', delimiter=',')\n",
        "\n",
        "backprop(10, 0.1, X, W1, W2)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_training_point:  1 \n",
            "\n",
            "(1, 3)\n",
            "[ 0.22861216 -0.08245127 -0.17208225  0.06348169]\n",
            "[ 0.22861216 -0.08245127 -0.17208225]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0df32309e0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-0df32309e0e3>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(num_trains, learning_rate, X, W1, W2)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"current_training_point: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_point\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-0df32309e0e3>\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(z2, a2, z3, y_hat, training_point)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# num_trains x 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mdw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 3 x 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULlxQRYnz44_"
      },
      "source": [
        "new_w1 = np.genfromtxt('ML_Colab/AND+XORmodelW1.csv', delimiter=',')\n",
        "\n",
        "new_w2 = np.genfromtxt('ML_Colab/AND+XORmodelW2.csv', delimiter=',')\n",
        "\n",
        "Null, Null, Null, y_hat = forward_prop(X, new_w1, new_w2)\n",
        "y_hat = np.rint(y_hat)\n",
        "print(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZbcXrs0HcV"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}