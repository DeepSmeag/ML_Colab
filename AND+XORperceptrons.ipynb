{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AND+XORperceptrons.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmqVpafJEawQ8cA1zOWPmx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepSmeag/ML_Colab/blob/main/AND%2BXORperceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSD-ubxddEbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37405525-ada2-4156-989e-b6f846eb1f6f"
      },
      "source": [
        "!git clone https://github.com/DeepSmeag/ML_Colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_Colab'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 47 (delta 19), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTnxk8iadYti"
      },
      "source": [
        "First we load the project so we get access to the files. Then we read the files of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdoKlQNwdYRj"
      },
      "source": [
        "def read_file(file_path):\n",
        "  dataset=[]\n",
        "  with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.strip()\n",
        "      parts = line.split(',')\n",
        "      x0,x1,y1,y2 = float(parts[0]), float(parts[1]), float(parts[2]), float(parts[3])\n",
        "      dataset.append((x0,x1,y1,y2))\n",
        "    return dataset\n",
        "\n",
        "dataset = read_file('ML_Colab/datasetAND+XOR.csv')\n",
        "\"\"\"it could also work with numpy and/or pandas to read the whole csv file at the\n",
        "same time, probably more efficient too\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBz_LId6fAam"
      },
      "source": [
        "We now have our dataset ready for use, next let's go and make the vectors for use with our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8Oo0fsfMsz"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndtPJIvjWle"
      },
      "source": [
        "#first layer is input, meaning we take the first 2 columns of the dataset\n",
        "num_trains = len(dataset)\n",
        "X = np.ones((num_trains,1)) \n",
        "#now we add the bias to every training instance\n",
        "X = np.append(X, np.array(dataset)[:,0:2], axis=1)\n",
        "# now we take the outputs\n",
        "Y = np.array(dataset)[:,2:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCs5cTggxQZ",
        "outputId": "371234d0-1714-4815-8244-750db48b3e89"
      },
      "source": [
        "#now we create Numpy arrays so that we have our weights\n",
        "#the first layer\n",
        "W1 = np.random.uniform(-1,1,(3,3))\n",
        "#the second\n",
        "W2 = np.random.uniform(-1,1,(4,2))\n",
        "print(\"W1:\\n\",W1,\"\\n\")\n",
        "print(\"W2:\\n\",W2,\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1:\n",
            " [[ 0.22105208  0.45989343  0.8962145 ]\n",
            " [-0.29059798 -0.66071029  0.42552441]\n",
            " [ 0.8886772   0.64210247 -0.41972825]] \n",
            "\n",
            "W2:\n",
            " [[-0.49555902 -0.35758057]\n",
            " [ 0.80103087  0.90833057]\n",
            " [-0.93637443  0.19890325]\n",
            " [-0.95843084 -0.20458579]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTXmd0W6n3sY",
        "outputId": "d3b73fd4-75ef-4434-f87b-3a959cb92ed3"
      },
      "source": [
        "#Now we're getting to the fun stuff\n",
        "#First, defining the necessary functions\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "#Forward Propagation\n",
        "def forward_prop():\n",
        "  #calculating the steps\n",
        "  t1 = sigmoid(np.matmul(X, W1))\n",
        "  t1 = np.insert(t1, 0, np.ones((num_trains,)), axis = 1)\n",
        "  t2 = sigmoid(np.matmul(t1, W2))\n",
        "  return t2\n",
        "forward_prop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.21322532, 0.53076434],\n",
              "       [0.23374786, 0.58628928],\n",
              "       [0.216369  , 0.50219577],\n",
              "       ...,\n",
              "       [0.23374786, 0.58628928],\n",
              "       [0.216369  , 0.50219577],\n",
              "       [0.23303745, 0.56177254]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCjkG9R3u74D",
        "outputId": "6b4a6232-52be-42db-e4f6-9effa4858463"
      },
      "source": [
        "#Ok, so that was forward propagation\n",
        "#Now, the NN should also be able to learn, so we have to implement Backprop\n",
        "#Since we're guessing at best at the moment as to the correct outputs\n",
        "#We have to define several functions for Backprop to work\n",
        "#These include the partial derivatives with which we'll update the weights matrices W1 and W2\n",
        "#And also the backprop itself which will go over epochs or whatever we may call it\n",
        "def sigmoid_gradient(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))\n",
        "def derivative():\n",
        "  return \n",
        "\n",
        "def backprop(epochs, learning_rate):\n",
        "  for i in range(epochs):\n",
        "    y_hat = forward_prop()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19661193324148185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNi9VDPNvOb6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}