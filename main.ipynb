{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq45Ni1zEX8ZF6laJ17SGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepSmeag/ML_Colab/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TdtQNoACTeZ",
        "outputId": "1b81691a-d4e7-4dbf-bf6c-fc8a6a359214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/DeepSmeag/ML_Colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_Colab'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZrldnhcBBDN"
      },
      "source": [
        "First time we will implement a simple AND gate using a small neural network, the legandary perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I68R5KSI8_6_"
      },
      "source": [
        "def read_file(file_path):\n",
        "  dataset=[]\n",
        "  with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.strip()\n",
        "      parts = line.split(',')\n",
        "      x0,x1,y = float(parts[0]), float(parts[1]), float(parts[2])\n",
        "      dataset.append((x0,x1,y))\n",
        "    return dataset\n",
        "\n",
        "dataset = read_file('ML_Colab/datasetAND.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6XzcCKEFTPe"
      },
      "source": [
        "We now have a read-from-file function and we have this simple model with inputs and outputs (columns 1,2 - in ; column 3 - out)\n",
        "So now we create the train function\n",
        "But first, keeping this block as an import function dump\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCRKj7qVFc0U"
      },
      "source": [
        "import random\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cAiVJ9gJiIg"
      },
      "source": [
        "Now we create the train function, along with the feed_forward function that \"predicts\" the outcome and all the necessary auxiliaries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut6x2Gi8JZ5v",
        "outputId": "73c93f95-baea-451f-a1c1-8481ee60dfb9"
      },
      "source": [
        "def activation_func(a):\n",
        "  return a\n",
        "\n",
        "def derivative(a):\n",
        "  return 1\n",
        "def compute_deltas(learning_rate, err, x0, x1, derivative):\n",
        "  dw0 = learning_rate * err * derivative(err) * x0\n",
        "  dw1 = learning_rate * err * derivative(err) * x1\n",
        "  db = learning_rate * derivative(err) * 1\n",
        "  return [dw0, dw1, db]\n",
        "\n",
        "def backprop_errors(perceptron, deltas):\n",
        "  for i in range(len(perceptron)):\n",
        "    perceptron[i] += deltas[i]\n",
        "\n",
        "def feed_forward(x0, x1, perceptron, activation_func):\n",
        "  w0 = perceptron[0]\n",
        "  w1 = perceptron[1]\n",
        "  b = perceptron[2]\n",
        "  a = x0*w0 + x1*w1 + b \n",
        "  return activation_func(a)\n",
        "\n",
        "\n",
        "def train_perceptron(dataset, epochs, learning_rate):\n",
        "  w0 = random.random()\n",
        "  w1 = random.random()\n",
        "  b = random.random()\n",
        "  perceptron = [w0,w1,b]\n",
        "\n",
        "  for i in range(epochs):\n",
        "    for train_instance in dataset:\n",
        "      x0,x1,y = train_instance\n",
        "      o = feed_forward(x0, x1, perceptron, activation_func)\n",
        "      err = o - y\n",
        "      deltas = compute_deltas(learning_rate, err, x0, x1, derivative)\n",
        "      backprop_errors(perceptron, deltas)\n",
        "  return perceptron\n",
        "\n",
        "print(train_perceptron(dataset, 1, 0.001))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.307326127184876, 0.006644551876695401, 0.8218099671480774]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14l538nzlXgV"
      },
      "source": [
        "This is a test\n"
      ]
    }
  ]
}